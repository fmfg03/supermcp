# üöÄ SuperMCP - Sistema Unificado de IA

**TODO lo que necesitas en una interfaz unificada:**
- üé™ **Swarm Intelligence**: 11 agentes inteligentes con comportamiento emergente
- ü§ñ **Multi-Model Router**: Todos los modelos (APIs + locales) con optimizaci√≥n autom√°tica
- üåâ **SAM.CHAT Integration**: Interfaz natural de lenguaje
- üí∞ **Cost Optimization**: Prioriza modelos locales gratuitos

---

## üéØ Lo que el sistema integra:

### üî• APIs Externas:
- **OpenAI** (GPT-4o, GPT-3.5)
- **Claude** (Opus, Sonnet) 
- **DeepSeek** (DeepSeek-Coder)
- **Perplexity** (Sonar)
- **Google AI** (Gemini Pro)

### üíª Modelos Locales:
- **Llama 3** (70B) - GRATIS
- **Codestral** (22B) - GRATIS
- **Cualquier modelo Ollama** - GRATIS

### üß† Router Inteligente:
```python
# Selecci√≥n autom√°tica por especializaci√≥n:
- C√≥digo ‚Üí DeepSeek Coder (prioridad 1)
- Research ‚Üí Perplexity (prioridad 1) 
- An√°lisis ‚Üí Claude Opus (prioridad 1)
- Chat general ‚Üí Local models (gratis)
- Traducci√≥n ‚Üí Google AI (barato)
```

### üí∞ Optimizaci√≥n de Costos:
```python
# Sistema prioriza por:
1. Modelos locales (costo = $0)
2. Modelos baratos para tareas simples  
3. Modelos premium solo cuando sea necesario
4. Fallback autom√°tico si falla un modelo
```

---

## üöÄ Inicio R√°pido

### 1. Configurar APIs (opcional)
```bash
# Copiar plantilla de configuraci√≥n
cp .env.template .env

# Editar .env y agregar tus API keys (dejar en blanco para saltar)
nano .env
```

### 2. Instalar modelos locales (opcional pero recomendado)
```bash
# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Descargar modelos gratuitos
ollama pull llama3:70b      # Modelo general
ollama pull codestral:22b   # Modelo para c√≥digo
```

### 3. Iniciar el sistema completo
```bash
chmod +x start_swarm_demo.sh
./start_swarm_demo.sh
```

### 4. Acceder a las interfaces
- ü§ñ **Multi-Model Router**: http://localhost:8300
- üåâ **SAM.CHAT Gateway**: http://localhost:8402  
- üìä **Dashboard Visual**: http://localhost:8401
- üîå **Swarm Core**: ws://localhost:8400

---

## üåê Endpoints Unificados

### Multi-Model Router (Puerto 8300)

#### Generaci√≥n General
```bash
curl -X POST http://localhost:8300/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Explica la teor√≠a de relatividad",
    "task_type": "general",
    "max_tokens": 1000
  }'
```

#### Generaci√≥n de C√≥digo (usa DeepSeek autom√°ticamente)
```bash
curl -X POST http://localhost:8300/code \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Crea una funci√≥n Python para calcular fibonacci",
    "max_tokens": 500
  }'
```

#### Research (usa Perplexity autom√°ticamente)
```bash
curl -X POST http://localhost:8300/research \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "√öltimas tendencias en inteligencia artificial 2024",
    "max_tokens": 2000
  }'
```

#### An√°lisis (usa Claude Opus autom√°ticamente)
```bash
curl -X POST http://localhost:8300/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Analiza los pros y contras de los microservicios",
    "max_tokens": 1500
  }'
```

#### Chat (usa modelos locales primero)
```bash
curl -X POST http://localhost:8300/chat \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Hola, ¬øc√≥mo est√°s?",
    "max_tokens": 500
  }'
```

### SAM.CHAT Gateway (Puerto 8402)

#### Procesamiento de Lenguaje Natural
```bash
curl -X POST http://localhost:8402/api/swarm/process \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Necesito que el swarm analice datos de mercado"
  }'
```

#### Control del Swarm
```bash
# Estado del swarm
curl http://localhost:8402/api/swarm/status

# Lista de agentes
curl http://localhost:8402/api/swarm/agents

# Crear tarea
curl -X POST http://localhost:8402/api/swarm/tasks \
  -H "Content-Type: application/json" \
  -d '{"description": "Analizar tendencias de IA"}'
```

---

## üé™ Agentes del Swarm

| Agente | Especialidad | Casos de Uso |
|--------|-------------|--------------|
| **Manus** | Coordinaci√≥n estrat√©gica | Planificaci√≥n, gesti√≥n |
| **SAM** | Ejecuci√≥n aut√≥noma | Automatizaci√≥n, tareas complejas |
| **Memory** | Gesti√≥n de contexto | Historial, aprendizaje |
| **GoogleAI** | IA especializada | An√°lisis, inferencia |
| **Notion** | Gesti√≥n del conocimiento | Documentaci√≥n |
| **Email** | Comunicaci√≥n | Notificaciones |
| **Web** | Investigaci√≥n web | Scraping, datos |
| **Analytics** | An√°lisis de datos | M√©tricas, insights |
| **Search** | B√∫squeda y filtrado | Descubrimiento |
| **MultiModel** | Router de IA | Selecci√≥n autom√°tica de modelos |

---

## üí° Ejemplos de Uso

### Ejemplo 1: Desarrollo de Software
```bash
# El sistema autom√°ticamente usa DeepSeek para c√≥digo
curl -X POST http://localhost:8300/code \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Crear una API REST en Python con FastAPI para gesti√≥n de usuarios",
    "max_tokens": 2000
  }'
```

### Ejemplo 2: Investigaci√≥n
```bash
# El sistema autom√°ticamente usa Perplexity para research
curl -X POST http://localhost:8300/research \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "√öltimos avances en computaci√≥n cu√°ntica y sus aplicaciones",
    "max_tokens": 3000
  }'
```

### Ejemplo 3: An√°lisis Empresarial
```bash
# El sistema autom√°ticamente usa Claude Opus para an√°lisis
curl -X POST http://localhost:8300/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Analizar impacto de la IA en el sector financiero",
    "max_tokens": 2500
  }'
```

### Ejemplo 4: Chat Casual (GRATIS)
```bash
# El sistema usa modelos locales (costo = $0)
curl -X POST http://localhost:8300/chat \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Cuenta un chiste sobre programadores",
    "max_tokens": 300
  }'
```

### Ejemplo 5: Coordinaci√≥n del Swarm
```bash
# Asignar tarea compleja al swarm completo
curl -X POST http://localhost:8402/api/swarm/process \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Crear un plan de marketing completo para una startup de IA"
  }'
```

---

## üéØ Comandos desde SAM.CHAT

### Comandos Directos
```
/swarm-status                    # Estado del swarm
/swarm-agents                    # Lista de agentes
/swarm-task [descripci√≥n]        # Asignar tarea
/swarm-consensus [propuesta]     # Iniciar consenso
/swarm-dashboard                 # URL del dashboard
```

### Lenguaje Natural
```
"Analiza las tendencias del mercado de criptomonedas"
"Genera c√≥digo Python para una calculadora"
"Busca informaci√≥n sobre energ√≠as renovables"
"El swarm deber√≠a decidir sobre migrar a microservicios"
"Necesito ayuda con an√°lisis de datos"
```

---

## üîß Caracter√≠sticas Avanzadas

### ü§ñ Selecci√≥n Autom√°tica de Modelos
- **C√≥digo**: DeepSeek-Coder (especializado + barato)
- **Research**: Perplexity (acceso a web + actualizado)
- **An√°lisis**: Claude Opus (razonamiento superior)
- **Chat**: Llama3 local (gratis + r√°pido)
- **Traducci√≥n**: Google AI (especializado + barato)

### üí∞ Optimizaci√≥n de Costos
```json
{
  "priority_order": [
    "1. Modelos locales (Llama3, Codestral) - $0",
    "2. Modelos baratos (Google AI, DeepSeek) - $0.0005-0.0014",
    "3. Modelos premium (Claude, GPT-4) - $0.003-0.015",
    "4. Fallback autom√°tico si falla modelo"
  ]
}
```

### üîÑ Fallback Autom√°tico
1. Intenta modelo primario
2. Si falla ‚Üí modelo secundario
3. Si falla ‚Üí modelo terciario
4. Reporta errores y estad√≠sticas

### üß† Inteligencia Emergente
- Detecci√≥n de patrones de comportamiento
- Liderazgo emergente autom√°tico
- Optimizaci√≥n din√°mica de roles
- Consenso democr√°tico

---

## üìä Monitoreo y M√©tricas

### Dashboard Web (http://localhost:8401)
- Vista en tiempo real del swarm
- M√©tricas de rendimiento
- Gr√°fico de comunicaciones
- Estad√≠sticas de costos

### API de Estad√≠sticas
```bash
# Estad√≠sticas del router
curl http://localhost:8300/stats

# Estado del swarm
curl http://localhost:8402/api/swarm/status

# Modelos disponibles
curl http://localhost:8300/models
```

### Logs del Sistema
```bash
# Ver logs en tiempo real
tail -f logs/multimodel_router.log    # Router de IA
tail -f logs/swarm_core.log          # Core del swarm
tail -f logs/sam_chat_gateway.log    # Gateway SAM.CHAT
tail -f logs/swarm_agents.log        # Agentes demo
```

---

## üö® Soluci√≥n de Problemas

### Problema: "No models available"
```bash
# Verificar configuraci√≥n de APIs
grep -v "^#" .env

# Verificar Ollama local
ollama list
ollama serve
```

### Problema: "Swarm disconnected"
```bash
# Verificar puerto del swarm
netstat -tlnp | grep 8400

# Reiniciar sistema
./start_swarm_demo.sh
```

### Problema: "High costs"
```bash
# Usar solo modelos locales
curl -X POST http://localhost:8300/generate \
  -d '{"prompt":"test", "budget_limit":0.0}'

# Verificar uso de modelos gratuitos
curl http://localhost:8300/stats
```

---

## üéØ Casos de Uso Empresariales

### 1. Centro de Desarrollo
- **C√≥digo**: DeepSeek autom√°tico
- **Review**: Claude Opus para an√°lisis
- **Docs**: Modelos locales para ahorro
- **Research**: Perplexity para tecnolog√≠as

### 2. Departamento de Marketing
- **An√°lisis**: Claude Opus para insights
- **Creatividad**: Modelos locales gratuitos
- **Research**: Perplexity para tendencias
- **Coordinaci√≥n**: Swarm para proyectos complejos

### 3. Equipos de Investigaci√≥n
- **Research**: Perplexity para papers recientes
- **An√°lisis**: Claude Opus para interpretaci√≥n
- **Traducci√≥n**: Google AI multiidioma
- **Colaboraci√≥n**: Swarm para consenso

---

## üé™ ¬°Sistema Completo Listo!

El SuperMCP es tu **centro de comando unificado** para toda la inteligencia artificial:

‚úÖ **11 agentes inteligentes** trabajando en equipo  
‚úÖ **Todos los modelos principales** con selecci√≥n autom√°tica  
‚úÖ **Optimizaci√≥n de costos** que prefiere modelos locales gratuitos  
‚úÖ **Fallback autom√°tico** entre modelos  
‚úÖ **Interfaz natural** desde SAM.CHAT  
‚úÖ **Monitoreo en tiempo real** con dashboard web  
‚úÖ **Inteligencia emergente** del swarm  

**¬°Accede a todo desde una sola interfaz!** üöÄ