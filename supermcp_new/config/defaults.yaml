# SuperMCP Default Configuration

# Application Settings
app:
  name: "SuperMCP"
  version: "2.0.0"
  debug: false
  host: "0.0.0.0"
  port: 8000

# Swarm Intelligence Settings
swarm:
  port: 8400
  max_agents: 50
  consensus_timeout: 300
  heartbeat_interval: 60
  emergent_detection: true

# Multi-Model AI Settings
ai:
  providers:
    openai:
      enabled: true
      model: "gpt-4"
      max_tokens: 4000
    anthropic:
      enabled: true
      model: "claude-3-sonnet-20240229"
      max_tokens: 4000
    google:
      enabled: true
      model: "gemini-pro"
      max_tokens: 4000
    local:
      enabled: true
      ollama_host: "sam.chat:11434"
      models: ["llama3", "codestral", "deepseek-coder"]

# MCP Server Settings
mcp:
  servers:
    filesystem:
      port: 8600
      enabled: true
      max_file_size: 10485760  # 10MB
    browser:
      port: 8601
      enabled: true
      headless: true
    knowledge:
      port: 8602
      enabled: true
      max_context_items: 1000
    developer:
      port: 8603
      enabled: true
    version_control:
      port: 8604
      enabled: true
    search:
      port: 8605
      enabled: true

# Security Settings
security:
  secret_key: "change-this-in-production"
  token_expire_minutes: 30
  encryption:
    algorithm: "HS256"
  cors:
    origins: ["http://sam.chat:3000", "http://sam.chat:8080"]

# Database Settings
database:
  url: "postgresql://user:password@sam.chat/supermcp"
  pool_size: 10
  max_overflow: 20
  echo: false

# Redis Settings
redis:
  url: "redis://sam.chat:6379"
  decode_responses: true

# Monitoring Settings
monitoring:
  metrics:
    enabled: true
    port: 9090
  logging:
    level: "INFO"
    format: "json"
  health_checks:
    enabled: true
    interval: 30

# Terminal Agent Settings
terminal:
  port: 8500
  security_level: "moderate"
  max_command_timeout: 300
  sandbox_mode: true